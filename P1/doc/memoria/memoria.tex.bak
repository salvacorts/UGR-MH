\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{imakeidx}
\usepackage{dirtree}

\usepackage[linesnumbered]{algorithm2e}
\SetKwRepeat{Do}{do}{while}%

\usepackage{xcolor}
\usepackage{listings}
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue}
}


\title{
\textbf{Metaheurística - Práctica 1.a} \\
Técnicas de Búsqueda Local y Algoritmos Greedy para el Problema de la Asignación Cuadrática
}

\author{
3º Grado Ingeniería Informática, Grupo 3 (Miércoles)\\
Salvador Corts Sánchez, 75935233C \\
salvacorts@correo.ugr.es
}

\date{}

\fancyhead[LE,RO]{Salvador Corts Sánchez, 75935233C}
\fancyhead[RE,LO]{QAP: Práctica 1}
\pagestyle{fancy}

\makeindex

\begin{document}
   % Header
   \maketitle
   
   % Index
   \newpage
   \tableofcontents

   
   % Descripción del problema
   \newpage
   \section{Descripción del problema}
   El problema de asignación cuadrática (en inglés, quadratic assignment problem, QAP) es uno de los problemas de optimización combinatoria más conocidos. En él se dispone de n unidades y n localizaciones en las que situarlas, por lo que el problema consiste en encontrar la asignación óptima de cada unidad a una localización. La nomenclatura “cuadrático” proviene de la función objetivo que mide la bondad de una asignación, la cual considera el producto de dos términos, la distancia entre cada par de localizaciones y el flujo que circula entre cada par de unidades. El QAP se puede formular como:
   
   $$QAP = 
\begin{matrix}
min\\
\pi \in \prod_N 
\end{matrix}   \Bigg( \sum_{i=1}^{n} \sum_{j=1}^{n} f_{ij}d_{\pi(i)\pi(j)} \Bigg)   
   $$
   
   donde:
   \begin{itemize}
      \item \textbf{$\pi$} es una solución al problema que consiste en una permutación que representa la asignación de la unidad $i$ a la localización  $\pi(i)$.
      
      \item $f_{ij}$ es el flujo que circula entre la unidad $i$ y la $j$.
      
      \item $d_{kl}$ es la distancia existente entre la localización $k$ y la $l$.
   \end{itemize}
   
   
   % Descripción de la aplicación de los algoritmos
   \newpage
   \section{Consideraciones comunes a los algoritmos utilizados}
   Esta práctica ha sido diseñada como una librería de metaheurísticas per se. Es decir, existe un tipo de objeto \textbf{Solution} y un tipo de objeto \textbf{Solver} del cual heredarán los objetos que implementan las diversas metaheurísticas. Cada metaheurística deberá implementar la función \textit{Solve} que devuelve un objeto \textbf{Solution}.
   
   \subsection*{Clase Solver}
   Esta clase debe ser heredada por las metaheurísticas a implementar. Su representación consta de dos matrices:
   \begin{itemize}
      \item \textbf{Distancias}: Matriz de distancias entre un punto $i$ y otro $j$.
      \item \textbf{Frecuencias}: Matriz de flujo entre un objeto $i$ y otro $j$. 
   \end{itemize}
   Tiene una función virtual llamada \textit{Solve} que ha de ser implementada por los objetos que hereden de \textbf{Solver}. Es la interfaz común a todos los objetos de tipo Solver para obtener una Solución.
   
   \newpage
   \subsection*{Clase Solution}
   Sirve para representar una solución, la cual, se implementa como un vector donde cada posición $i$ representa un objeto y alberga la localización $j$ donde debe ser colocado dicho objeto $i$. 
   
   \begin{center}
      \includegraphics[scale=0.14]{solRep}
   \end{center}
   
   Existe una función \textit{CalcCost} que calcula el coste de dicha solución como:
      $$cost = \sum_{i=1}^{n}\sum_{j=1, j \neq i}^{n} f_{ij}d_{\pi(i)\pi(j)}$$
   donde:
   \begin{itemize}
      \item $\pi$ es la solución al problema.
      
      \item $f_{ij}$ es el flujo que circula entre la unidad $i$ y la $j$.
      
      \item $d_{kl}$ es la distancia existente entre la localización $k$ y la $l$.
   \end{itemize}\vspace*{0.5cm}
   
   Dado que el cálculo del coste de la solución es bastante costoso, $O(n^{2})$, Esta función debe llamarse manualmente al menos una vez para obtener el coste y que este se guarde en la representación de la clase.
   
   
   \newpage
   \section{Algoritmo Greedy}
   Se basa en el cálculo de los potenciales de flujo y distancia definidos como:
   \begin{center}
      $\hat{f}_i = \sum_{j=1}^{n}f_{ij}$ \hspace*{1cm} $\hat{d}_i = \sum_{j=1}^{n}d_{ij}$
   \end{center}
   
   El algoritmo irá seleccionando la unidad $i$ libre con mayor $\hat{f}_i$ y le asignará la localización $j$ libre con menor $\hat{d}_j$. Su implementación en pseudocódigo es la siguiente:  
      \begin{algorithm}
          \# Calcula los potenciales\\
          $dp = fp = vector(n)$\\
          \For{$i=0$ \KwTo $n$}{
             $\hat{f}_i = \hat{d}_i = 0$\\
             \For{$j=0$ \KwTo $n$}{
                $\hat{f}_i = \hat{f}_i + f_{ij}$\\
                $\hat{d}_i = \hat{d}_i + d_{ij}$\\
             }
             $dp_i = \hat{d}_i$\\
             $fp_i = \hat{f}_i$\\
          }\vspace*{0.5cm}
          
          \# Calcula la mejor combinación. $\pi$ es la representación de la solución\\
          $locAssigned = unitAssigned = vector(n)\{0\}$\\
          \For{$i=0$ \KwTo $n$}{
             $best\hat{f} = -\infty$;\hspace*{0.5cm}$best\hat{f}_{index}=0$\\
             $best\hat{d} = \infty$;\hspace*{0.5cm}$best\hat{d}_{index}=0$\\
             \For{$j=0$ \KwTo $n$}{
                $\hat{f}_i = fp_j$;\hspace*{0.5cm}$\hat{d}_i = dp_j$\\
                
                \If{$\hat{f}_i > best\hat{f}$ \textbf{and} $unitAssigned_j \neq 1$}{
                   $best\hat{f} = \hat{f}_i$;\hspace*{0.5cm}$best\hat{f}_{index}=j$\\
                }
                
                \If{$\hat{d}_i < best\hat{d}$  \textbf{and} $locAssigned_j \neq 1$}{
                   $best\hat{d} = \hat{d}_i$;\hspace*{0.5cm}$best\hat{d}_{index}=j$\\
                }
             }
             $\pi(best\hat{f}_{index}) = best\hat{d}_{index}$\\
             $unitAssigned_{best\hat{f}_{index}} = locAssigned_{best\hat{d}_{index}} = 1$\\             
          }
      \end{algorithm}
      
      
      \newpage
      \section{Algoritmo de Búsqueda Local}
      Vamos a utilizar una \textbf{búsqueda local del primer mejor}. Cuando se genera una solución vecina que mejora a la actual, se toma esta como solución y se pasa a la siguiente iteración. Se detiene la búsqueda cuando no se genera ningún vecino mejor que la solución actual. La implementación de dicha idea, que será la función \textit{Solve}, se puede ver como:
      \begin{algorithm}
         $\pi = GenerateInitialSolution()$ \# Será aleatoria\\
         \Do{$\exists \pi'$}{
            $\pi' = GenerateBestNeighbour(\pi)$
            
            \lIf{$\exists \pi'$}{$\pi = \pi'$}
         }
      \end{algorithm}
      
      A fin de minimizar el riesgo de quedarnos en un óptimo local, vamos a partir de una solución aleatoria en vez de partir de una solución greedy. Dicha solución aleatoria se genera de la siguiente manera:
      \begin{algorithm}
         $assigned = vector(n){0}$\\
         \For{$i=0$ \KwTo $n$}{
            \Do{$assigned_r \neq 0$}{
               $r = random() \ mod\ n$\\
             }
             
             $\pi(i) = r$\\
             $assigned_r = 1$\\
         }
      \end{algorithm}
      
      Como se comentó anteriormente, el proceso de cálculo del coste de la solución es de orden cuadrático por lo que realizar dicho calculo con cada vecino es sumamente costoso; En su lugar, vamos a considerar una \textbf{factorización} (con eficiencia $O(n)$) teniendo en cuenta solo los cambios realizados por el movimiento de intercambio para generar el vecino. El incremento del coste de cambiar el elemento en la posición r $r$ por el de $s$ se define como:
      $$
\Delta C(\pi,r,s) = \sum_{k=1, k\neq r,s}^{n}\begin{bmatrix}
f_{rk}(d_{\pi(s)\pi(k)} - d_{\pi(r)\pi(k)}) + f_{sk}(d_{\pi(r)\pi(k)} - d_{\pi(s)\pi(k)}) +\\ 
f_{kr}(d_{\pi(k)\pi(s)} - d_{\pi(k)\pi(r)}) + f_{ks}(d_{\pi(k)\pi(r)} - d_{\pi(k)\pi(s)})
\end{bmatrix} 
      $$
      
      Si $\Delta C(\pi,r,s) < 0$, el resultado de cambiar $r$ por $s$ es favorable, es decir, el costo es menor por lo que tomaremos el vecino resultante de este cambio como solución actual y generamos nuevos vecinos a partir de este.\\
      
      La función que hace uso de esta factorización para explorar los vecinos de una solución se implentaría como:
      \begin{algorithm}
         \SetKwProg{Def}{def}{:}{end}
         \Def{GenerateBestNeighbour($\pi$)}{
            \For{$r=0$ \KwTo $n/2$}{
               \For{$s=r+1$ \KwTo $n$}{                  
                  \If{$\Delta C(\pi,r,s) < 0$}{
                     $\pi' = \pi$\\
                     $t = \pi'(r)$\\
                     $\pi'(r) = \pi'(s)$\\
                     $\pi'(s) = t$\\
                     
                     \textbf{return} $\pi'$
                  }
               }
            }         
         }
      \end{algorithm}
      
      Como vemos, podemos reducir considerablemente el numero de iteraciones totales iterando en $r$ en el primer bucle hasta $n/2$ y en el segundo desde $r+1$ hasta $n$, ya que asi podemos evitar comparar dos veces el mismo moviemiento. Es lo mismo cambiar $r$ por $s$ que $s$ por $r$.
     
      
      \newpage
      \subsection*{Búsqueda Local con \textit{Don't Look Bits}}
      Como estamos utilizando una \textbf{búsqueda local del primer mejor}, podemos definir una lista de candidatos a la que llamamos \textbf{\textit{Don't Look Bits}} que reducirá significativamente el tiempo de ejecución.\\
      
      Se trata de un un vector de bits inicialmente a 0, esto nos indica que todos los movimientos pueden ser considerados. Si tras probar todos los movimientos asociados un bit no hemos encontrado ninguna mejora, cambiaremos el valor de dicho bit a 1, indicando que esta unidad no debe ser tenida en cuenta hasta que dicha unidad asociada a ese bit se vea implicada en un movimeinto que mejora la solución actual, en cuyo caso el bit será nuevamente 0.\\
      
      Podemos ejemplificar este algoritmo con el siguiente pseudocódigo:
      \begin{algorithm}
         $dlbMask = vector(n)\{0\}$ \# Don't look bits\\
         \SetKwProg{Def}{def}{:}{end}
         \Def{GenerateBestNeighbour($\pi$)}{
            \For{$r=0$ \KwTo $n$}{
               \lIf{$dlbMask_r \neq 0$}{\textbf{continue}}
               \For{$s=0$ \KwTo $n$}{                  
                  \If{$\Delta C(\pi,r,s) < 0$}{
                     $\pi' = \pi$\\
                     $t = \pi'(r)$\\
                     $\pi'(r) = \pi'(s)$\\
                     $\pi'(s) = t$\\
                     
                     $dlbMask_r = dlbMask_s = 0$\\
                     \textbf{return} $\pi'$
                  }
               }
               $dlbMask_r = 1$
            }         
         }
      \end{algorithm}
      
      
      \newpage
      \section{Procedimiento considerado para desarrollar la práctica}
      Esta práctica ha sido desarrolladaen \textbf{C++} como una librería de metaheurísticas. La estructura del proyecto es la siguiente:\\
      
      \dirtree{%
         .1 /Software.
         .2 bin/         \DTcomment{Archivos ejecutables}.
         .3 practica1   \DTcomment{Ejecutable principal de la práctica}.
         .2 build/       \DTcomment{Directorio para compilación con CMake}.
         .2 doc/         \DTcomment{Otra documentación y codigo LaTeX de este documento}.
         .2 include/     \DTcomment{Cabeceras}.
         .2 instancias/  \DTcomment{Instancias de problemas sobre QAP}.
         .3 *.dat   \DTcomment{Definición de un problema}.
         .3 *.sln   \DTcomment{Solución a un problema}.
         .2 src/         \DTcomment{Codigo fuente}.
         .2 CMakeLists.txt   \DTcomment{Instrucciones de compilación para CMake}.
         .2 readme.txt       \DTcomment{Instrucciones de uso}.
      }\vspace*{0.5cm}
      
      Para compilar este proyecto necesitamos las herramientas \textit{g++} y \textit{CMake}. Para instalarlas en un sistema \textbf{Ubuntu} o derivado, ejecutamos:
      
      \begin{lstlisting}[language=bash]
      sudo apt-get install g++ cmake 
      \end{lstlisting}
      
      Podemos compilar el proyecto con dos niveles de optimización:
      \begin{itemize}
         \item \textbf{Debug}: Sin optimización y con simbolos de depuración. Ejecutar CMake con opción \textit{-D CMAKE\_BUILD\_TYPE=Debug}
         
         \item \textbf{Release}: Máxima optimización en la compilación. Por defecto.
      \end{itemize}
      
      Se compila con las siguientes instrucciones:
      
      \begin{lstlisting}[language=bash]
   cd build/
   # Para debug: cmake -D CMAKE_BUILD_TYPE=Debug ..
   cmake ..  
   make clean
   make
   cd ..
      \end{lstlisting}
      
      \newpage
      La sintaxis de ejecución es la siguiente\footnote{Todo en la misma línea. El parametro semilla es opcional, por defecto $semilla = 7$}:
      \begin{lstlisting}[language=bash]
./bin/practica1 instancias/<problema>.dat 
                <ruta_escribir_solucion> 
                <semilla>
      \end{lstlisting}
      
      Por ejemplo:
      \begin{lstlisting}[language=bash]
./bin/practica1 instancias/chr22a.dat prueba.sln 12
      \end{lstlisting}
      
      La salida del programa tiene la siguiente estructura:
      \begin{center}
      \includegraphics[scale=0.7]{execOutDiagram}
      \end{center}
      
      
      \newpage
      \section{Experimentos y análisis de resultados}
      Con el fin de comparar los algoritmos implementados con los ya existentes, vamos a calcular para cada algorimo los siguientes parámetros:
      \begin{itemize}
         \item \textbf{\textit{Desv}}: Media de las desviaciones en porcentaje, del valor obtenido por cada método en cada instancia respecto al mejor valor conocido para ese caso.
         $$ \frac{1}{\left | casos \right |}\sum_{i=1}^{casos}100\frac{valoralgoritmo_i - mejorValor_i}{mejorValor_i} $$
         Obtendremos los mejores valores conocidos de \textit{QAPLIB}\footnote{http://anjos.mgi.polymtl.ca/qaplib//inst.html}
         
         \item \textbf{\textit{Tiempo}}: se calcula como la media del tiempo de ejecución empleado por el
algoritmo para resolver cada caso del problema.
      \end{itemize}
      
      Cuanto menor es el valor de Desv para un algoritmo, mejor calidad tiene dicho algoritmo. Por otro lado, si dos métodos obtienen soluciones de la misma calidad (tienen valores de Desv similares), uno será mejor que el otro si emplea menos tiempo en media.\\
      
\emph{\textbf{Parámetros del experimento:} 
   \begin{itemize}
      \item El valor de la semilla para este experimento es 7.
      \item Se compilara con parametro \textbf{debug} a fin de contrastar aún mas los resultados del tiempo.
   \end{itemize}
}      
      
      
   
\printindex
\end{document}
